# -*- coding: utf-8 -*-
"""SRGAN -Super Resolution GAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_A3hGmcm-db5Ha6u05D__JGxJCWgfOKv
"""

!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip
!unzip DIV2K_train_HR.zip

import torch
import math
import torchvision
from torchvision import transforms
from os import listdir
import numpy as np
from torch.autograd import Variable
from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize
from PIL import Image
from os.path import join
from torch.utils.data import Dataset
from torch.utils.data import DataLoader

torch.autograd.set_detect_anomaly(True)

UPSCALE_FACTOR = 4
CROPSIZE = 88

mean = np.array([0.485, 0.456, 0.406])
std = np.array([0.229, 0.224, 0.225])

"""Function for checking the details of the image"""

def is_image_file(filename):
    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])


def calculate_valid_crop_size(crop_size, upscale_factor):
    return crop_size - (crop_size % upscale_factor)


def train_hr_transform(crop_size):
    return Compose([
        RandomCrop(crop_size),
        ToTensor(),
    ])


def train_lr_transform(crop_size, upscale_factor):
    return Compose([
        ToPILImage(),
        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),
        ToTensor()
    ])


def display_transform():
    return Compose([
        ToPILImage(),
        Resize(400),
        CenterCrop(400),
        ToTensor()
    ])

class TrainDatasetFromFolder(Dataset):
  def __init__(self, dataset_dir, crop_size, upscale_factor):
    super(TrainDatasetFromFolder, self).__init__()
    self.image_filenames = [join(dataset_dir,x) for x in listdir(dataset_dir) if is_image_file(x)]
    crop_size = calculate_valid_crop_size(crop_size, upscale_factor)
    self.hr_transform = train_hr_transform(crop_size)
    self.lr_transform = train_lr_transform(crop_size, upscale_factor)


  def __getitem__(self, index):
    hr_image = self.hr_transform(Image.open(self.image_filenames[index]))
    lr_image = self.lr_transform(hr_image)
    return lr_image, hr_image


  def __len__(self):
    return len(self.image_filenames)

"""#### Training of the Model"""

train_set = TrainDatasetFromFolder("DIV2K_train_HR", crop_size=CROPSIZE, upscale_factor= UPSCALE_FACTOR)
trainloader = DataLoader(train_set, batch_size=64, num_workers=4, shuffle=True)

from torch import nn, optim

# Implementing the Model by class format

class ResidualBlock(nn.Module):
  def __init__(self, channels):
    super(ResidualBlock, self).__init__()
    self.conv1 = nn.Conv2d(channels, channels, kernel_size =3, padding=1)
    self.bn1 = nn.BatchNorm2d(channels)
    self.prelu = nn.PReLU()
    self.conv2 = nn.Conv2d(channels, channels, kernel_size =3, padding =1)
    self.bn2 = nn.BatchNorm2d(channels)

  def forward(self, x):
    residual = self.conv1(x)
    residual = self.bn1(residual)
    residual = self.prelu(residual)
    residual = self.conv2(residual)
    residual = self.bn2(residual)
    return x + residual

class UpsampleBlock(nn.Module):
  def __init__(self, in_channels, up_scale):
    super(UpsampleBlock, self).__init__()
    self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2,
                          kernel_size =3, padding =1)
    self.pixel_shuffle = nn.PixelShuffle(up_scale)
    self.prelu = nn.PReLU()

  def forward(self, x):
    x = self.conv(x)
    x = self.pixel_shuffle(x)
    x = self.prelu(x)
    return x

class Generator(nn.Module):
  def __init__(self, scale_factor):
    super(Generator, self).__init__()
    upsample_block_num = int(math.log(scale_factor, 2))

    self.block1 = nn.Sequential(
        nn.Conv2d(3, 64, kernel_size=9, padding=4),
        nn.PReLU()
    )

    self.block2 = ResidualBlock(64)
    self.block3 = ResidualBlock(64)
    self.block4 = ResidualBlock(64)
    self.block5 = ResidualBlock(64)
    self.block6 = ResidualBlock(64)
    self.block7 = nn.Sequential(
        nn.Conv2d(64, 64, kernel_size=3, padding=1),
        nn.BatchNorm2d(64)
    )
    block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]
    block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))
    self.block8 = nn.Sequential(*block8)
  def forward(self, x):
    block1 = self.block1(x)
    block2 = self.block2(block1)
    block3 = self.block3(block2)
    block4 = self.block4(block3)
    block5 = self.block5(block4)
    block6 = self.block6(block5)
    block7 = self.block7(block6)
    block8 = self.block8(block1 + block7)
    return (torch.tanh(block8) + 1) / 2

class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()
    self.net = nn.Sequential(
        nn.Conv2d(3, 64, kernel_size=3, padding=1),
        nn.LeakyReLU(0.2),

        nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),
        nn.BatchNorm2d(64),
        nn.LeakyReLU(0.2),

        nn.Conv2d(64, 128, kernel_size=3, padding=1),
        nn.BatchNorm2d(128),
        nn.LeakyReLU(0.2),

        nn.Conv2d(128, 256, kernel_size=3, padding=1),
        nn.BatchNorm2d(256),
        nn.LeakyReLU(0.2),

        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),
        nn.BatchNorm2d(256),
        nn.LeakyReLU(0.2),

        nn.Conv2d(256, 512, kernel_size=3, padding=1),
        nn.BatchNorm2d(512),
        nn.LeakyReLU(0.2),

        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),
        nn.BatchNorm2d(512),
        nn.LeakyReLU(0.2),

        nn.AdaptiveAvgPool2d(1),
        nn.Conv2d(512, 1024, kernel_size=1),
        nn.LeakyReLU(0.2),
        nn.Conv2d(1024, 1, kernel_size=1)
    )
  def forward(self, x):
    batch_size=x.size()[0]
    return torch.sigmoid(self.net(x).view(batch_size))

from torchvision.models.vgg import vgg19

# Now we got to make the Generator Loss
class TVLoss(nn.Module):
  def __init__(self, tv_loss_weight=1):
    super(TVLoss, self).__init__()
    self.tv_loss_weight=tv_loss_weight
  def forward(self, x):
    batch_size=x.size()[0]
    h_x = x.size()[2]
    w_x = x.size()[3]

    count_h = self.tensor_size(x[:, :, 1:, :])
    count_w = self.tensor_size(x[:, :, :, 1:])

    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()
    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()
    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size

  # Forgot to implement an important method
  @staticmethod # Must add this
  def tensor_size(t):
    return t.size()[1] * t.size()[2] * t.size()[3]

class GeneratorLoss(nn.Module):
  def __init__(self):
    super(GeneratorLoss, self).__init__()
    vgg = vgg19(pretrained=True)
    loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()
    for param in loss_network.parameters():
      param.requires_grad = False
    self.loss_network = loss_network
    self.mse_loss = nn.MSELoss()
    self.tv_loss = TVLoss()
  def forward(self, out_labels, out_images, target_images):
    adversial_loss = torch.mean(1 - out_labels)
    perception_loss = self.mse_loss(out_images, target_images)
    image_loss = self.mse_loss(out_images, target_images)
    tv_loss = self.tv_loss(out_images)
    return image_loss + 0.001 * adversial_loss + 0.006 * perception_loss + 2e-8 * tv_loss

device  = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# Standard device selectoin
device

netG = Generator(UPSCALE_FACTOR)
netD = Discriminator()

generator_criterion = GeneratorLoss()

generator_criterion = generator_criterion.to(device)
netG = netG.to(device)
netD = netD.to(device)

optimizerG = optim.Adam(netG.parameters(), lr=0.0002)
optimizerD = optim.Adam(netD.parameters(), lr=0.0002)

results = {
    "d_loss":[],
    "g_loss":[],
    "d_score":[],
    "g_score":[]
}

## Now for training code
from tqdm import tqdm
import os

N_EPOCHS = 100

for epoch in range(1, N_EPOCHS +1):
  train_bar =tqdm(trainloader)
  running_results = {'batch_sizes':0, 'd_loss':0,
                     "g_loss":0,"d_score":0,"g_score":0}

  netG.train()
  netD.train()
  for data, target in train_bar:
    g_update_first = True
    batch_size = data.size(0)
    running_results['batch_sizes'] += batch_size

    real_img = Variable(target)
    real_img = real_img.to(device)
    z = Variable(data)
    z = z.to(device)

    ## Update Discriminator ##
    fake_img = netG(z)
    netD.zero_grad()
    real_out = netD(real_img).mean()
    fake_out = netD(fake_img).mean()
    d_loss = 1 - real_out + fake_out
    d_loss.backward(retain_graph = True)
    optimizerD.step()

    ## Now update Generator
    fake_img = netG(z)
    fake_out = netD(fake_img).mean()
    netG.zero_grad()
    g_loss = generator_criterion(fake_out, fake_img, real_img)
    g_loss.backward()

    fake_img = netG(z)
    fake_out = netD(fake_img).mean()

    optimizerG.step()

    running_results['g_loss'] += g_loss.item() * batch_size
    running_results['d_loss'] += d_loss.item() * batch_size
    running_results['d_score'] += real_out.item() * batch_size
    running_results['g_score'] += real_out.item() * batch_size

    ## Updating the progress bar
    train_bar.set_description(desc="[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f" % (
        epoch, N_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],
        running_results['g_loss'] / running_results['batch_sizes'],
        running_results['d_score'] / running_results['batch_sizes'],
        running_results['g_score'] / running_results['batch_sizes']
    ))
  netG.eval()

import os

# Specify the directory path
directory = '/content/drive/MyDrive'

# Check if the directory exists, if not, create it
if not os.path.exists(directory):
    os.makedirs(directory)

# Save model to Google Drive
torch.save(netG.state_dict(), '/content/drive/MyDrive/srgan_model.pth')

import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

def compare_images(lr_img_path, hr_img_path):
    # Preprocess LR image
    lr_img = Image.open('/content/home.jpg')
    lr_img = lr_img.convert('RGB')
    lr_img = lr_img.resize((CROPSIZE // UPSCALE_FACTOR, CROPSIZE // UPSCALE_FACTOR), Image.BICUBIC)
    lr_img = np.array(lr_img).astype(np.float32)
    lr_img = lr_img / 255.0
    lr_img = (lr_img - mean) / std
    lr_img = np.transpose(lr_img, (2, 0, 1))
    lr_img = torch.from_numpy(lr_img).unsqueeze(0).to(device)

    # Convert lr_img to float
    lr_img = lr_img.float()

    # Generate SR image
    with torch.no_grad():
        netG.eval()
        sr_img = netG(lr_img).cpu().squeeze(0)

    sr_img = sr_img.detach().numpy()
    sr_img = np.transpose(sr_img, (1, 2, 0))
    sr_img = (sr_img * std) + mean
    sr_img = np.clip(sr_img, 0, 1)

    # Preprocess HR image
    hr_img = Image.open('/content/home.jpg')
    hr_img = hr_img.convert('RGB')
    hr_img = hr_img.resize((CROPSIZE, CROPSIZE), Image.BICUBIC)
    hr_img = np.array(hr_img).astype(np.float32)
    hr_img = hr_img / 255.0
    hr_img = (hr_img - mean) / std
    hr_img = np.transpose(hr_img, (2, 0, 1))
    hr_img = torch.from_numpy(hr_img).unsqueeze(0).to(device)

    # Convert hr_img to float
    hr_img = hr_img.float()

    # Display images
    mean_reshaped = np.reshape(mean, (3, 1, 1))
    std_reshaped = np.reshape(std, (3, 1, 1))

    lr_img = (lr_img.squeeze(0).cpu().numpy() * std_reshaped) + mean_reshaped
    lr_img = np.clip(lr_img, 0, 1)
    sr_img = (sr_img * 255).astype(np.uint8)
    sr_img = Image.fromarray(sr_img)
    hr_img = (hr_img.squeeze(0).cpu().numpy() * std_reshaped) + mean_reshaped
    hr_img = np.clip(hr_img, 0, 1)

    plt.figure(figsize=(15, 5))
    plt.subplot(1, 3, 1)
    plt.title('LR Image')
    plt.imshow(np.transpose(lr_img, (1, 2, 0)))

    plt.subplot(1, 3, 3)
    plt.title('SR Image')
    plt.imshow(np.transpose(hr_img, (1, 2, 0)))

    plt.show()

# Test the uploaded LR image with the actual HR image
compare_images('path_to_uploaded_LR_image.jpg', 'path_to_actual_HR_image.jpg')

